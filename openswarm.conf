# OpenSwarm Configuration
# This file configures agent implementation and LLM backend

# Agent Implementation: claude-code-cli | zeroclaw
AGENT_IMPL=${AGENT_IMPL:-claude-code-cli}

# LLM Backend (for Zeroclaw): anthropic | openai | openrouter | local | ollama
LLM_BACKEND=${LLM_BACKEND:-ollama}

# Local Model Path (for local llama.cpp backend)
LOCAL_MODEL_PATH=${LOCAL_MODEL_PATH:-./models/gpt-oss-20b.gguf}

# Model Name (for Ollama, OpenAI, or Anthropic)
# Ollama: gpt-oss:20b (recommended), llama3:70b, mistral:7b
# Anthropic: claude-opus-4, claude-sonnet-3.5
# OpenAI: gpt-4, gpt-3.5-turbo
# OpenRouter: minimax/minimax-m2.5, anthropic/claude-sonnet-4, openai/gpt-4.1
MODEL_NAME=${MODEL_NAME:-gpt-oss:20b}

# Auto-update Zeroclaw from upstream on startup (true|false)
ZEROCLAW_AUTO_UPDATE=${ZEROCLAW_AUTO_UPDATE:-true}

# API Keys (if using cloud providers)
# ANTHROPIC_API_KEY set via environment
# OPENAI_API_KEY set via environment
